{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8HS2t76Vrfo9lcqgC+2mk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import gc\n","\n","from torch.utils.data import DataLoader, random_split\n","from transformers import BertTokenizer\n","from datasets import load_dataset\n","\n","# from YOUR project\n","from src.model import (\n","    EncoderLSTM,\n","    DecoderLSTM,\n","    Seq2SeqLSTM,\n","    VisualAutoencoder,\n","    SequencePredictor\n",")\n","\n","from src.utils import (\n","    validation,\n","    compute_bleu,\n","    compute_perplexity,\n","    TextTaskDataset,\n","    AutoEncoderTaskDataset,\n","    save_checkpoint_to_drive,\n","    load_checkpoint_from_drive,\n","    init_weights\n",")\n","\n"],"metadata":{"id":"c2s82_L81NWG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oV3GnY8nkYj"},"outputs":[],"source":["# Variables and initial setup\n","torch.cuda.empty_cache()\n","gc.collect()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","N_EPOCHS = 5\n","emb_dim = 16\n","latent_dim = 16\n","num_layers = 1\n","dropout = True\n","\n","# Initializing the NLP models\n","encoder = EncoderLSTM(tokenizer.vocab_size, emb_dim, latent_dim, num_layers, dropout).to(device)\n","decoder = DecoderLSTM(tokenizer.vocab_size, emb_dim, latent_dim, num_layers, dropout).to(device)\n","text_autoencoder = Seq2SeqLSTM(encoder, decoder).to(device)\n","text_autoencoder, _, _, _ = load_checkpoint_from_drive(text_autoencoder, None, filename='text_autoencoder.pth')\n","\n","total_params = sum(p.numel() for p in text_autoencoder.parameters())\n","print(f\"Total parameters (Not trainable): {total_params}\")\n","# Deactivating training from this model for efficiency (although not ideal)\n","for param in text_autoencoder.parameters():\n","        param.requires_grad = False\n","\n","\n","\n","# Initialize the main architecture\n","# We put all the sizes the same, not ideal as well\n","sequence_predictor = SequencePredictor(visual_autoencoder, text_autoencoder, latent_dim, latent_dim) # gru_hidden_size is latent_dim (16)\n","sequence_predictor.to(device)\n","\n","#  Print number of trainable parameters\n","total_params = sum(p.numel() for p in sequence_predictor.parameters() if p.requires_grad)\n","print(f\"Total trainable parameters in the whole model: {total_params}\")\n","\n","# Print model size\n","total_params = sum(p.numel() for p in sequence_predictor.parameters())\n","print(f\"Total parameters: {total_params}\")\n","\n","\n","\n","#Training tools\n","criterion_images = nn.L1Loss()\n","criterion_ctx = nn.MSELoss()\n","criterion_text = nn.CrossEntropyLoss(ignore_index=tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n","optimizer = torch.optim.Adam(sequence_predictor.parameters(), lr=0.001)\n","\n","\n","#Training loop for the sequence predictor\n","# Instantiate the model, define loss and optimizer\n","\n","sequence_predictor.train()\n","losses = []\n","metrics = []\n","for epoch in range(N_EPOCHS):\n","\n","\n","    running_loss = 0.0\n","    for frames, descriptions, image_target, text_target  in train_dataloader:\n","\n","      # Send images and tokens to the GPU\n","      descriptions = descriptions.to(device)\n","      frames = frames.to(device)\n","      image_target = image_target.to(device)\n","      text_target = text_target.to(device)\n","      # Predictions from our model\n","      pred_image_content, pred_image_context, predicted_text_logits_k, _, _ = sequence_predictor(frames, descriptions, text_target)\n","      # Computing losses\n","      # Loss for image reconstruction\n","      loss_im = criterion_images(pred_image_content, image_target)\n","      # Loss for the average pattern the images contain\n","      mu_global = frames.mean(dim=[0, 1])\n","      mu_global = mu_global.unsqueeze(0).expand_as(pred_image_context)\n","      loss_context = criterion_ctx(pred_image_context, mu_global)\n","      # Loss function for the text prediction\n","      prediction_flat = predicted_text_logits_k.reshape(-1, tokenizer.vocab_size)\n","      target_labels = text_target.squeeze(1)[:, 1:] # Slice to get [8, 119]\n","      target_flat = target_labels.reshape(-1)\n","      loss_text = criterion_text(prediction_flat, target_flat)\n","      # Combining the losses\n","      loss = loss_im + loss_text + 0.2*loss_context\n","      # Optimizing\n","      optimizer.zero_grad()\n","      loss.backward() # Corrected: Removed accidental '+'\n","      optimizer.step()\n","\n","      running_loss += loss.item() * frames.size(0)\n","\n","    # checking model performance on validation set\n","    sequence_predictor.eval()\n","    print(\"Validation on training dataset\")\n","    print( \"----------------\")\n","    train_bleu, train_ppl = validation( sequence_predictor, train_dataloader )\n","    print(\"Validation on validation dataset\")\n","    print( \"----------------\")\n","    val_bleu, val_ppl = validation( sequence_predictor, val_dataloader)\n","    sequence_predictor.train()\n","\n","    # scheduler.step()\n","    epoch_loss = running_loss / len(train_dataloader.dataset)\n","    losses.append(epoch_loss)\n","    print(f'Epoch [{epoch+1}/{N_EPOCHS}], Loss: {epoch_loss:.4f}')\n","    print(f'Train BLEU: {train_bleu:.4f}, Train PPL: {train_ppl:.4f},' f'Val BLEU: {val_bleu:.4f}, Val PPL: {val_ppl:.4f}')\n","    # â˜… ADD: Save epoch metrics to table\n","    metrics.append({\n","    \"epoch\": epoch+1,\n","    \"loss\": epoch_loss,\n","    \"train_bleu\": train_bleu,\n","    \"train_ppl\": train_ppl,\n","    \"val_bleu\": val_bleu,\n","    \"val_ppl\": val_ppl\n","})\n","\n","\n","\n","    if epoch % 5 == 0:\n","      save_checkpoint_to_drive(sequence_predictor, optimizer, epoch, epoch_loss, filename=f\"sequence_predictor.pth\")\n","\n"]}]}