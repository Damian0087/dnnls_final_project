{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtf2qiBbygch04XPsVDOaf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","import os\n","import torch\n","import torch.nn as nn\n","import gc\n","\n","from torch.utils.data import DataLoader, random_split\n","from transformers import BertTokenizer\n","from datasets import load_dataset\n","from transformers import BertTokenizer\n","\n","\n","from src.model import (\n","    EncoderLSTM,\n","    DecoderLSTM,\n","    Seq2SeqLSTM,\n","    VisualAutoencoder,\n","    SequencePredictor\n",")\n","\n","from src.utils import (\n","    validation,\n","    compute_bleu,\n","    compute_perplexity,\n","    TextTaskDataset,\n","    AutoEncoderTaskDataset,\n","    save_checkpoint_to_drive,\n","    load_checkpoint_from_drive,\n","    init_weights,\n","    val_dataloader,\n","    train_dataloader)\n","\n"],"metadata":{"id":"c2s82_L81NWG","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1767210316615,"user_tz":0,"elapsed":87,"user":{"displayName":"UGOCHUKWU TONY-OKONTA","userId":"00828561908584827048"}},"outputId":"6bb65f57-935c-415c-86ff-1c0a4c181fef"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'src'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-267390965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from src.model import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mEncoderLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mDecoderLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\",  padding=True, truncation=True)\n","visual_autoencoder = VisualAutoencoder(latent_dim=16)\n","visual_autoencoder.apply(init_weights)\n","\n","total_params = sum(p.numel() for p in visual_autoencoder.parameters() if p.requires_grad)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"OuLqgBnoQOpG","executionInfo":{"status":"error","timestamp":1767200875141,"user_tz":0,"elapsed":35,"user":{"displayName":"UGOCHUKWU TONY-OKONTA","userId":"00828561908584827048"}},"outputId":"2a45e1e5-1344-4933-875c-e17396f6f31b"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'BertTokenizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3464473846.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google-bert/bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisual_autoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisual_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvisual_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oV3GnY8nkYj"},"outputs":[],"source":["# Variables and initial setup\n","torch.cuda.empty_cache()\n","gc.collect()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","N_EPOCHS = 5\n","emb_dim = 16\n","latent_dim = 16\n","num_layers = 1\n","dropout = True\n","\n","# Initializing the NLP models\n","encoder = EncoderLSTM(tokenizer.vocab_size, emb_dim, latent_dim, num_layers, dropout).to(device)\n","decoder = DecoderLSTM(tokenizer.vocab_size, emb_dim, latent_dim, num_layers, dropout).to(device)\n","text_autoencoder = Seq2SeqLSTM(encoder, decoder).to(device)\n","text_autoencoder, _, _, _ = load_checkpoint_from_drive(text_autoencoder, None, filename='text_autoencoder.pth')\n","\n","total_params = sum(p.numel() for p in text_autoencoder.parameters())\n","print(f\"Total parameters (Not trainable): {total_params}\")\n","# Deactivating training from this model for efficiency (although not ideal)\n","for param in text_autoencoder.parameters():\n","        param.requires_grad = False\n","\n","\n","\n","# Initialize the main architecture\n","# We put all the sizes the same, not ideal as well\n","sequence_predictor = SequencePredictor(visual_autoencoder, text_autoencoder, latent_dim, latent_dim) # gru_hidden_size is latent_dim (16)\n","sequence_predictor.to(device)\n","\n","#  Print number of trainable parameters\n","total_params = sum(p.numel() for p in sequence_predictor.parameters() if p.requires_grad)\n","print(f\"Total trainable parameters in the whole model: {total_params}\")\n","\n","# Print model size\n","total_params = sum(p.numel() for p in sequence_predictor.parameters())\n","print(f\"Total parameters: {total_params}\")\n","\n","\n","\n","#Training tools\n","criterion_images = nn.L1Loss()\n","criterion_ctx = nn.MSELoss()\n","criterion_text = nn.CrossEntropyLoss(ignore_index=tokenizer.convert_tokens_to_ids(tokenizer.pad_token))\n","optimizer = torch.optim.Adam(sequence_predictor.parameters(), lr=0.001)\n","\n","\n","#Training loop for the sequence predictor\n","# Instantiate the model, define loss and optimizer\n","\n","sequence_predictor.train()\n","losses = []\n","metrics = []\n","for epoch in range(N_EPOCHS):\n","\n","\n","    running_loss = 0.0\n","    for frames, descriptions, image_target, text_target  in train_dataloader:\n","\n","      # Send images and tokens to the GPU\n","      descriptions = descriptions.to(device)\n","      frames = frames.to(device)\n","      image_target = image_target.to(device)\n","      text_target = text_target.to(device)\n","      # Predictions from our model\n","      pred_image_content, pred_image_context, predicted_text_logits_k, _, _ = sequence_predictor(frames, descriptions, text_target)\n","      # Computing losses\n","      # Loss for image reconstruction\n","      loss_im = criterion_images(pred_image_content, image_target)\n","      # Loss for the average pattern the images contain\n","      mu_global = frames.mean(dim=[0, 1])\n","      mu_global = mu_global.unsqueeze(0).expand_as(pred_image_context)\n","      loss_context = criterion_ctx(pred_image_context, mu_global)\n","      # Loss function for the text prediction\n","      prediction_flat = predicted_text_logits_k.reshape(-1, tokenizer.vocab_size)\n","      target_labels = text_target.squeeze(1)[:, 1:] # Slice to get [8, 119]\n","      target_flat = target_labels.reshape(-1)\n","      loss_text = criterion_text(prediction_flat, target_flat)\n","      # Combining the losses\n","      loss = loss_im + loss_text + 0.2*loss_context\n","      # Optimizing\n","      optimizer.zero_grad()\n","      loss.backward() # Corrected: Removed accidental '+'\n","      optimizer.step()\n","\n","      running_loss += loss.item() * frames.size(0)\n","\n","    # checking model performance on validation set\n","    sequence_predictor.eval()\n","    print(\"Validation on training dataset\")\n","    print( \"----------------\")\n","    train_bleu, train_ppl = validation( sequence_predictor, train_dataloader )\n","    print(\"Validation on validation dataset\")\n","    print( \"----------------\")\n","    val_bleu, val_ppl = validation( sequence_predictor, val_dataloader)\n","    sequence_predictor.train()\n","\n","    # scheduler.step()\n","    epoch_loss = running_loss / len(train_dataloader.dataset)\n","    losses.append(epoch_loss)\n","    print(f'Epoch [{epoch+1}/{N_EPOCHS}], Loss: {epoch_loss:.4f}')\n","    print(f'Train BLEU: {train_bleu:.4f}, Train PPL: {train_ppl:.4f},' f'Val BLEU: {val_bleu:.4f}, Val PPL: {val_ppl:.4f}')\n","    # â˜… ADD: Save epoch metrics to table\n","    metrics.append({\n","    \"epoch\": epoch+1,\n","    \"loss\": epoch_loss,\n","    \"train_bleu\": train_bleu,\n","    \"train_ppl\": train_ppl,\n","    \"val_bleu\": val_bleu,\n","    \"val_ppl\": val_ppl\n","})\n","\n","\n","\n","    if epoch % 5 == 0:\n","      save_checkpoint_to_drive(sequence_predictor, optimizer, epoch, epoch_loss, filename=f\"sequence_predictor.pth\")\n","\n"]}]}